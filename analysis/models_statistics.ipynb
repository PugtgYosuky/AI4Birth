{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utils import get_raw_results, get_mean_results, models_statistical_test\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'roc_auc_score' : 'AUCROC',\n",
    "    'f1_weighted' : 'F1-score',\n",
    "    'precision_weighted' : 'PPV',\n",
    "    'NPV' : 'NPV',\n",
    "    'recall_weighted' : 'Sensitivity',\n",
    "    'specificity' : 'Specificity',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = 'LogisticRegression'\n",
    "test_metric = 'roc_auc_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(raw_results, main_model, variability=True):\n",
    "    main_model_df = pd.DataFrame(raw_results[main_model])\n",
    "    results = {}\n",
    "    for model in raw_results.keys():\n",
    "        print(model)\n",
    "        aux = {}\n",
    "        df = pd.DataFrame(raw_results[model])\n",
    "        for metric, metric_name in metrics.items():\n",
    "            if variability:\n",
    "                aux[metric_name] = f'{df[metric].mean():.3f}Â±{df[metric].std():.3f}'\n",
    "            else:\n",
    "                aux[metric_name] = f'{df[metric].mean():.3f}'\n",
    "        if variability:\n",
    "            if model == main_model:\n",
    "                aux['p-value'] = 'Reference'\n",
    "            else:\n",
    "                pvalue = models_statistical_test(main_model_df[test_metric], df[test_metric])\n",
    "                aux['p-value'] = pvalue\n",
    "        results[model] = aux\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df.index.name = 'Model'\n",
    "    results_df = results_df.reset_index()\n",
    "    results_df.sort_values(by='AUCROC', ascending=False, inplace=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests across model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../tests/test1/cv-PT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = get_raw_results(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_table(raw_results, 'LogisticRegression')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../data/results/models_results_CV_PT.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis - compare solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = {\n",
    "    '../tests/test1/cv-PT' : 'LR CV All Features',\n",
    "    '../tests/test1/cv-PT-reduced-13' : 'LR CV 13 Best Features',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric = 'roc_auc_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = {}\n",
    "for path, name in solutions.items():\n",
    "    print(name)\n",
    "    raw_results.update({name : get_raw_results(path)[main_model]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_df = pd.DataFrame(raw_results['LR CV All Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_table(raw_results, 'LR CV All Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../data/results/models_results_compare_CV_PT_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Analysis - US dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = {\n",
    "    '../tests/test1/train-PT-test-US' : 'LR TT All Features',\n",
    "    '../tests/test1/train-PT-test-US-reduced-13' : 'LR TT 13 Best Features',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric = 'roc_auc_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_results = {}\n",
    "for path, name in solutions.items():\n",
    "    print(name)\n",
    "    raw_results.update({name : get_raw_results(path)[model_test]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model_df = pd.DataFrame(raw_results['LR TT All Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_table(raw_results, 'LR TT All Features', variability=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../data/results/models_results_compare_TT_PT_reduced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deliveries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
