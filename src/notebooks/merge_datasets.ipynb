{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset for complete mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from map_vars import all_variables, common_variables\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_variables_func = all_variables\n",
    "test_name = 'test1'\n",
    "use_race = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_race == None:\n",
    "    df_us = pd.read_csv('../../data/CSL_StudyItems/dataset_americans.csv')\n",
    "else:\n",
    "    df_us = pd.read_csv('../../data/CSL_StudyItems/dataset_americans_with_race.csv')\n",
    "    # select pretended race\n",
    "    df_us = pd.DataFrame(df_us.loc[df_us['momrace_new'] == use_race])\n",
    "    df_us.drop(columns=['momrace_new'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt = pd.read_csv('../../data/PT/PT_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get variables mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_vars = []\n",
    "pt_vars = []\n",
    "\n",
    "for key, value in map_variables_func.items():\n",
    "    if isinstance(value, dict):\n",
    "        for subkey, subvalue in value.items():\n",
    "            pt_vars.append((key+'_'+subkey).replace(' ', ''))\n",
    "            us_vars.append(subvalue)\n",
    "    else:\n",
    "        pt_vars.append(key.replace(' ', ''))\n",
    "        us_vars.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df_us[us_vars].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df_pt[pt_vars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle duplicate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_vars = pd.DataFrame(zip(pt_vars, us_vars), columns=['PT', 'US'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitive_vars = map_vars[map_vars.duplicated('US', keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitive_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_vars = {}\n",
    "for pt, us in repetitive_vars.itertuples(index=False):\n",
    "    if us in duplicate_vars:\n",
    "        duplicate_vars[us].append(pt)\n",
    "    else:\n",
    "        duplicate_vars[us] = [pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for us, pts in duplicate_vars.items(): # use the first one as the main variable\n",
    "    df_pt[us] = df_pt[pts].max(axis=1)\n",
    "    df_pt.drop(columns=pts, inplace=True)\n",
    "    map_vars = map_vars.loc[map_vars['PT'].isin(pts) == False]\n",
    "    # add the new mapping\n",
    "    map_vars = pd.concat([map_vars, pd.DataFrame(dict(PT=[us], US=[us]))], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(map_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets with the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt = pd.DataFrame(df_pt[map_vars['PT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_us = pd.DataFrame(df_us[map_vars['US']])\n",
    "data_us.columns = map_vars['PT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_us.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirm results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.concat([data_pt.dtypes, data_us.dtypes], axis=1)\n",
    "dtypes.columns = ['PT', 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_dtypes = dtypes.loc[dtypes['PT'] != dtypes['US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in different_dtypes.index:\n",
    "    print(feature)\n",
    "    print(f'PT: {data_pt[feature].dtype}, US: {data_us[feature].dtype}')\n",
    "    print('PT', data_pt[feature].unique())\n",
    "    print('US', data_us[feature].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert class to bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt['Class'] = data_pt['Class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_us['Class'] = data_us['Class'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert boolean features from bool to float in US dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_features = data_us.select_dtypes(include=bool).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in bool_features:\n",
    "    data_us[feature] = data_us[feature].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handle features with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.concat([data_pt.dtypes, data_us.dtypes], axis=1)\n",
    "dtypes.columns = ['PT', 'US']\n",
    "different_dtypes = dtypes.loc[dtypes['PT'] != dtypes['US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in different_dtypes.index:\n",
    "    print(feature)\n",
    "    print(f'PT: {data_pt[feature].dtype}, US: {data_us[feature].dtype}')\n",
    "    print('PT', data_pt[feature].unique())\n",
    "    print('US', data_us[feature].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt['Paridade'] = data_pt['Paridade'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt['Idade'] = data_pt['Idade'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt['AE'] = data_pt['AE'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert CSAAnt to int and drop nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_us['CSAAnt'] = data_us['CSAAnt'].astype(float)\n",
    "data_pt['CSAAnt'] = data_pt['CSAAnt'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert PPTAnterior to True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt['PPTAnterior'] = (data_pt['PPTAnterior'] >= 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_us['PatologiasPrevias_2-hipotiroidismo'] = data_us['PatologiasPrevias_2-hipotiroidismo'].astype(float)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_us['IG'] = data_us.IG.round(0).astype(int) # convert IG to weeks and without floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confirm transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.concat([data_pt.dtypes, data_us.dtypes], axis=1)\n",
    "dtypes.columns = ['PT', 'US']\n",
    "different_dtypes = dtypes.loc[dtypes['PT'] != dtypes['US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in different_dtypes.index:\n",
    "    print(feature)\n",
    "    print(f'PT: {data_pt[feature].dtype}, US: {data_us[feature].dtype}')\n",
    "    print('PT', data_pt[feature].unique())\n",
    "    print('US', data_us[feature].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_path = f'../../data/{test_name}'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_race:\n",
    "    data_pt.to_csv(f'../../data/{test_name}/PT_dataset_mapped_{use_race}.csv', index=False)\n",
    "    data_us.to_csv(f'../../data/{test_name}/US_dataset_mapped_{use_race}.csv', index=False)\n",
    "else:\n",
    "    data_pt.to_csv(f'../../data/{test_name}/PT_dataset_mapped.csv', index=False)\n",
    "    data_us.to_csv(f'../../data/{test_name}/US_dataset_mapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_dataset = pd.concat([data_pt, data_us], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_race:\n",
    "    combine_dataset.to_csv(f'../../data/{test_name}/combine_dataset_mapped_{use_race}.csv', index=False)\n",
    "else:\n",
    "    combine_dataset.to_csv(f'../../data/{test_name}/combine_dataset_mapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.read_csv(f'../../data/{test_name}/PT_dataset_mapped.csv')\n",
    "us = pd.read_csv(f'../../data/{test_name}/US_dataset_mapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us.columns[us.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = pd.concat([pt.dtypes, us.dtypes], axis=1)\n",
    "dtypes.columns = ['PT', 'US']\n",
    "different_dtypes = dtypes.loc[dtypes['PT'] != dtypes['US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us[us.columns[us.isnull().any()]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deliveries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
